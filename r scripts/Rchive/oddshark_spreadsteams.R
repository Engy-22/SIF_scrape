# load libraries and set working directory to repo
library(rvest)
library(plyr)
library(stringr)
setwd("~/G_WD/SIF_scrape")

# run phantomjs javascript file to render javascript variables and save as html in working directory
system("./phantomjs scrape_oddshark.js")

# read html file generated by phantomjs
html = read_html('oddshark.html')

# scrape week
week_raw = html %>%
    html_nodes(".header-text") %>%
    html_text(trim = TRUE)
dir.create(paste("./output/", week_raw, sep = ""))
week = gsub(",", "", strsplit(week_raw, " ")[[1]][2])
week = as.integer(as.character(week))

# scrape teams
oddsshark_team_name = html %>%
    html_nodes(".city") %>%
    html_text()

# scrape lines
spread = html %>%
    html_nodes(".value") %>%
    html_text()

# bind scrapes into dataframe
spreads = as.data.frame(cbind(oddsshark_team_name, spread), stringsAsFactors = FALSE)

# clean lines data
spreads$spread = gsub("EV", 0, spreads$spread)
spreads$spread = as.numeric(spreads$spread)

# add underdog, week, and timestamp columns
spreads$underdog = as.integer(as.logical(spreads$spread > 0))
spreads$week = week
spreads$update_ts = Sys.time()

# output to .csv
write.csv(spreads, paste("./output/", week_raw,"/Spreads_", Sys.Date(),".csv", sep = ""), row.names = FALSE)

