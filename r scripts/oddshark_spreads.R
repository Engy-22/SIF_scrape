# load libraries and set working directory to repo
library(rvest)
library(plyr)
library(stringr)
setwd("~/G_WD/SIF_scrape")

# run phantomjs javascript file to render javascript variables and save as html in working directory
system("./phantomjs scrape_oddshark.js")

# read html file generated by phantomjs
html = read_html('oddshark.html')

# scrape week
week_raw = "Week 1, 2017"

# scrape teams
oddsshark_team_name = html %>%
    html_nodes(".city") %>%
    html_text()

# scrape lines
lines = html %>%
    html_nodes(".value") %>%
    html_text()

# clean lines data
lines = gsub("EV", 0, lines)
matchup = paste(oddsshark_team_name[c(TRUE,FALSE)], oddsshark_team_name[c(FALSE,TRUE)], sep = "") 
oddshark_spread = lines[c(TRUE,FALSE)]

# bind scrapes into dataframe
spreads = as.data.frame(cbind(matchup, oddshark_spread), 
                        stringsAsFactors = FALSE)
spreads$oddshark_spread = abs(as.numeric(spreads$oddshark_spread))

# merge game_ids and add timestamp column
map = read.csv("./maps/map1.csv", header = TRUE, stringsAsFactors = FALSE)[,c("game_id", "matchup")]
spreads = merge(map, spreads, by = "matchup")
spreads$update_ts = Sys.time()
spreads = spreads[order(spreads$game_id),]

# output to .csv
write.csv(spreads, 
          paste("./output/", week_raw, "/", Sys.Date(),"/oddshark_", Sys.Date() ,".csv", sep = ""),
          row.names = FALSE)

