# load libraries and set working directory to repo
library(rvest)
library(plyr)
library(stringr)
setwd("~/G_WD/SIF_scrape")

# run phantomjs javascript file to render javascript variables and save as html in working director
system("./phantomjs scrape_oddshark.js")

# read html file generated by phantomjs
html = read_html('oddshark.html')

# define function to trim output vector
trim = function (x) gsub("^\\s+|\\s+$", "", x)

# scrape, trim, and split teams data from node
teams = html %>%
    html_nodes(".teams") %>%
    html_text()
teams = trim(teams)
teams = str_split_fixed(teams, " ", 2)

# scrape, trim, and split lines data from node
lines = html %>%
    html_nodes(".lines") %>%
    html_text()
lines = trim(lines)
lines = str_split_fixed(lines, " ", 2)

# bind data together in spreads data frame, name columns, and timestamp it
spreads = as.data.frame(cbind(teams, lines))
colnames(spreads) = c("away", "home", "away_spread", "home_spread")
spreads$timestamp = Sys.time()

# output to .csv
write.csv(spreads, paste("./output/Spreads_", Sys.Date(),".csv", sep = ""), row.names = FALSE)
