# load libraries and set working directory to repo
library(rvest)
library(plyr)
library(stringr)
setwd("~/G_WD/SIF_scrape")

# run phantomjs javascript file to render javascript variables and save as html in working directory
system("./phantomjs scrape_oddshark.js")

# read html file generated by phantomjs
html = read_html('oddshark.html')

# scrape week
week = html %>%
    html_nodes(".header-text") %>%
    html_text()
week = gsub(",", "", strsplit(week, " ")[[1]][2])
week = as.numeric(as.character(week))

# scrape teams
team = html %>%
    html_nodes(".city") %>%
    html_text()

# scrape lines
line = html %>%
    html_nodes(".value") %>%
    html_text()

# bind scrapes into dataframe
spreads = as.data.frame(cbind(team, line), stringsAsFactors = FALSE)

# clean lines data
spreads$line = gsub("EV", 0, spreads$line)
spreads$line = as.numeric(spreads$line)

# add underdog, week, and timestamp columns
spreads$underdog = as.integer(as.logical(spreads$line > 0))
spreads$week = week
spreads$timestamp = Sys.time()

# output to .csv
write.csv(spreads, paste("./output/Spreads_", Sys.Date(),".csv", sep = ""), row.names = FALSE)

